# Issue 0005: 層化サンプリング結果の評価・運用フロー詳細化

## 背景
層化サンプリングの導入後、分布達成度やモデル性能への寄与を継続的に確認し、再実行プロセスを運用に乗せる必要があります。本Issueでは評価指標・自動化フロー・ドキュメント化のタスクを細分化します。

## タスク
1. **分布評価レポートの詳細化**
   - サンプリング前後の分布を比較する指標（KLダイバージェンス、Jensen-Shannon距離、各ビンの達成率）を定義し、自動生成するスクリプトを実装する。
   - 分布比較結果をダッシュボードまたはNotebookで可視化し、閾値超過時に警告を出す仕組みを整備する。
   - 評価対象のデータセット（mini/full、本番実行分）ごとにレポートテンプレートを作成する。
2. **モデル性能評価の設計**
   - サンプリング適用前後のデータセットでE2Eモデル（または代表タスクのサロゲートモデル）を学習し、指標（操舵角MAE、位置誤差、成功率など）を比較するプロトコルを策定する。
   - 希少シナリオに焦点を当てた評価セット（Issue 0002のビン定義に沿う）を抽出し、モデル性能変化を可視化する。
   - 計算リソースと実行頻度（例：四半期ごと、主要リリース前）の要件をまとめる。
3. **運用・再実行フローの確立**
   - 新規データ投入時にパイプラインを再実行する手順書を作成し、入力データ検証→クリップ生成→サンプリング→評価レポート出力までのステップを明記する。
   - CI/CDまたはバッチジョブ化に向けて、環境設定、スケジューラ（Airflow, Argo等）、監視ポイント（ログ、メトリクス）を定義する。
   - 再実行時の差分管理（既存クリップとの重複排除、再サンプリング方針）とロールバック手順を策定する。
4. **モニタリングとフィードバックサイクル**
   - 運用時に監視すべき指標（希少ビンのカバレッジ、サンプリング失敗数、CAN欠損率、モデル性能のトレンド）をリスト化し、収集方法を決める。
   - 定期レビュー会議の頻度・参加者・議題テンプレートを決定し、改善提案の起票フローを明文化する。

## 必要な追加情報
- モデル性能を測定する際のベースラインモデル仕様および利用可能なコンピューティングリソース。
- 運用環境で利用しているスケジューラ／監視基盤（例：Prometheus, Grafana）の制約。
- 分布評価で許容される乖離の基準値（ビジネス側KPI）と報告フォーマット。

## 成果物
- 分布評価スクリプトと可視化レポート（テンプレート含む）。
- モデル性能比較の評価プロトコル・結果サマリー。
- 再実行フロー、ジョブ設定、モニタリング指標をまとめた運用ドキュメント。
